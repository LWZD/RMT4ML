
<!DOCTYPE html
  PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head>
      <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
   <!--
This HTML was auto-generated from MATLAB code.
To make changes, update the MATLAB code and republish this document.
      --><title>Section 3.2: Covariance distance estimation</title><meta name="generator" content="MATLAB 9.6"><link rel="schema.DC" href="http://purl.org/dc/elements/1.1/"><meta name="DC.date" content="2020-07-07"><meta name="DC.source" content="cov_distance_estimation.m"><style type="text/css">
html,body,div,span,applet,object,iframe,h1,h2,h3,h4,h5,h6,p,blockquote,pre,a,abbr,acronym,address,big,cite,code,del,dfn,em,font,img,ins,kbd,q,s,samp,small,strike,strong,sub,sup,tt,var,b,u,i,center,dl,dt,dd,ol,ul,li,fieldset,form,label,legend,table,caption,tbody,tfoot,thead,tr,th,td{margin:0;padding:0;border:0;outline:0;font-size:100%;vertical-align:baseline;background:transparent}body{line-height:1}ol,ul{list-style:none}blockquote,q{quotes:none}blockquote:before,blockquote:after,q:before,q:after{content:'';content:none}:focus{outine:0}ins{text-decoration:none}del{text-decoration:line-through}table{border-collapse:collapse;border-spacing:0}

html { min-height:100%; margin-bottom:1px; }
html body { height:100%; margin:0px; font-family:Arial, Helvetica, sans-serif; font-size:10px; color:#000; line-height:140%; background:#fff none; overflow-y:scroll; }
html body td { vertical-align:top; text-align:left; }

h1 { padding:0px; margin:0px 0px 25px; font-family:Arial, Helvetica, sans-serif; font-size:1.5em; color:#d55000; line-height:100%; font-weight:normal; }
h2 { padding:0px; margin:0px 0px 8px; font-family:Arial, Helvetica, sans-serif; font-size:1.2em; color:#000; font-weight:bold; line-height:140%; border-bottom:1px solid #d6d4d4; display:block; }
h3 { padding:0px; margin:0px 0px 5px; font-family:Arial, Helvetica, sans-serif; font-size:1.1em; color:#000; font-weight:bold; line-height:140%; }

a { color:#005fce; text-decoration:none; }
a:hover { color:#005fce; text-decoration:underline; }
a:visited { color:#004aa0; text-decoration:none; }

p { padding:0px; margin:0px 0px 20px; }
img { padding:0px; margin:0px 0px 20px; border:none; }
p img, pre img, tt img, li img, h1 img, h2 img { margin-bottom:0px; } 

ul { padding:0px; margin:0px 0px 20px 23px; list-style:square; }
ul li { padding:0px; margin:0px 0px 7px 0px; }
ul li ul { padding:5px 0px 0px; margin:0px 0px 7px 23px; }
ul li ol li { list-style:decimal; }
ol { padding:0px; margin:0px 0px 20px 0px; list-style:decimal; }
ol li { padding:0px; margin:0px 0px 7px 23px; list-style-type:decimal; }
ol li ol { padding:5px 0px 0px; margin:0px 0px 7px 0px; }
ol li ol li { list-style-type:lower-alpha; }
ol li ul { padding-top:7px; }
ol li ul li { list-style:square; }

.content { font-size:1.2em; line-height:140%; padding: 20px; }

pre, code { font-size:12px; }
tt { font-size: 1.2em; }
pre { margin:0px 0px 20px; }
pre.codeinput { padding:10px; border:1px solid #d3d3d3; background:#f7f7f7; }
pre.codeoutput { padding:10px 11px; margin:0px 0px 20px; color:#4c4c4c; }
pre.error { color:red; }

@media print { pre.codeinput, pre.codeoutput { word-wrap:break-word; width:100%; } }

span.keyword { color:#0000FF }
span.comment { color:#228B22 }
span.string { color:#A020F0 }
span.untermstring { color:#B20000 }
span.syscmd { color:#B28C00 }

.footer { width:auto; padding:10px 0px; margin:25px 0px 0px; border-top:1px dotted #878787; font-size:0.8em; line-height:140%; font-style:italic; color:#878787; text-align:left; float:none; }
.footer p { margin:0px; }
.footer a { color:#878787; }
.footer a:hover { color:#878787; text-decoration:underline; }
.footer a:visited { color:#878787; }

table th { padding:7px 5px; text-align:left; vertical-align:middle; border: 1px solid #d6d4d4; font-weight:bold; }
table td { padding:7px 5px; text-align:left; vertical-align:top; border:1px solid #d6d4d4; }





  </style></head><body><div class="content"><h1>Section 3.2: Covariance distance estimation</h1><!--introduction--><p>This page contains simulations in Section 3.2: estimation of various distance between covariance matrices in large dimension</p><!--/introduction--><h2>Contents</h2><div><ul><li><a href="#1">Visualization of behavior of <img src="cov_distance_estimation_eq17534740922011065178.png" alt="$x \mapsto x m_\mu(x)$"></a></li><li><a href="#2">Classical versus random matrix improved covariance distance estimator</a></li><li><a href="#3">FUNCTIONS</a></li></ul></div><h2 id="1">Visualization of behavior of <img src="cov_distance_estimation_eq17534740922011065178.png" alt="$x \mapsto x m_\mu(x)$"></h2><pre class="codeinput">close <span class="string">all</span>; clear; clc

coeff = 3;
p = 100*coeff;
n1 = 300*coeff;
n2 = 900*coeff;

c1 = p/n1;
c2 = p/n2;

rng(928);
Z1 = randn(p,n1);
Z2 = randn(p,n2);

eig_C1 = [1,2,4];
eig_C2 = [1,3,5];
C1 = diag([eig_C1(1)*ones(p/3,1); eig_C1(2)*ones(p/3,1); eig_C1(3)*ones(p/3,1)]);
C2 = diag([eig_C2(1)*ones(p/3,1); eig_C2(2)*ones(p/3,1); eig_C2(3)*ones(p/3,1)]);

X1 = sqrtm(C1)*Z1;
X2 = sqrtm(C2)*Z2;

SCM1 = X1*(X1')/n1;
SCM2 = X2*(X2')/n2;

SCM = SCM1\SCM2;
eigs_SCM = eig(SCM);
eigs_SCM = sort(eigs_SCM);

m = @(x) sum(1./(eigs_SCM-x))/p;
x_m = @(x) x.*m(x);

tol1 = 1e-3;
index_eigs_SCM = 50;
zoom_eigs_SCM = linspace(eigs_SCM(index_eigs_SCM)-tol1,eigs_SCM(index_eigs_SCM+1)+tol1,1000);

tol2 = 1e-4;
zoom_eigs_SCM(zoom_eigs_SCM&lt;=eigs_SCM(index_eigs_SCM)+tol2 &amp; zoom_eigs_SCM&gt;=eigs_SCM(index_eigs_SCM)-tol2)=NaN;
zoom_eigs_SCM(zoom_eigs_SCM&lt;=eigs_SCM(index_eigs_SCM+1)+tol2 &amp; zoom_eigs_SCM&gt;=eigs_SCM(index_eigs_SCM+1)-tol2)=NaN;

<span class="comment">% numerical evaluation of eta and zeta</span>
eta = real(eig(diag(eigs_SCM) + sqrt(eigs_SCM)*sqrt(eigs_SCM')/(n1-p)));
eta = eta(eta&lt;eigs_SCM(index_eigs_SCM+1) &amp; eta&gt;eigs_SCM(index_eigs_SCM));
zeta = real(eig(diag(eigs_SCM) - sqrt(eigs_SCM)*sqrt(eigs_SCM')/(n2)));
zeta = zeta(zeta&lt;eigs_SCM(index_eigs_SCM) &amp; zeta&gt;eigs_SCM(index_eigs_SCM-1));

figure
hold <span class="string">on</span>
plot(zoom_eigs_SCM, x_m(zoom_eigs_SCM));
xline(eigs_SCM(index_eigs_SCM),<span class="string">'--k'</span>);
xline(eigs_SCM(index_eigs_SCM+1),<span class="string">'--k'</span>);
yline(0,<span class="string">'--k'</span>);
yline( (1-c2)/c2,<span class="string">'--k'</span>);
yline( -1/c1,<span class="string">'--k'</span>);
yline(0,<span class="string">'--k'</span>);
axis([eigs_SCM(index_eigs_SCM)-tol1 eigs_SCM(index_eigs_SCM+1)+tol1 -10 10])

xlabel(<span class="string">'x'</span>, <span class="string">'Interpreter'</span>, <span class="string">'latex'</span>)
ylabel(<span class="string">'$x m_{\mu}(x)$'</span>, <span class="string">'Interpreter'</span>, <span class="string">'latex'</span>)
plot(eigs_SCM(index_eigs_SCM),0,<span class="string">'ob'</span>);
text(eigs_SCM(index_eigs_SCM)+1e-5,.5,<span class="string">'$\lambda_i$'</span>, <span class="string">'Interpreter'</span>, <span class="string">'latex'</span>, <span class="string">'FontSize'</span>,12)
plot(eigs_SCM(index_eigs_SCM+1),0,<span class="string">'ob'</span>);
text(eigs_SCM(index_eigs_SCM+1)+1e-5,.5,<span class="string">'$\lambda_{i+1}$'</span>, <span class="string">'Interpreter'</span>, <span class="string">'latex'</span>, <span class="string">'FontSize'</span>,12)

plot(eta, 0,<span class="string">'xr'</span>);
plot(zeta, 0,<span class="string">'xr'</span>);
text(eta-1e-4, .5,<span class="string">'$\eta_i$'</span>, <span class="string">'Interpreter'</span>, <span class="string">'latex'</span>, <span class="string">'FontSize'</span>,12)
text(zeta-1e-4, .5,<span class="string">'$\zeta_i$'</span>, <span class="string">'Interpreter'</span>, <span class="string">'latex'</span>, <span class="string">'FontSize'</span>,12)
xline(eta,<span class="string">':k'</span>);
xline(zeta,<span class="string">':k'</span>);
</pre><img vspace="5" hspace="5" src="cov_distance_estimation_01.png" alt=""> <h2 id="2">Classical versus random matrix improved covariance distance estimator</h2><pre class="codeinput">close <span class="string">all</span>; clear; clc

p_loop = 2.^(1:9);
n1 = 1024;
n2 = 2048;

rng(928);
nb_average_loop = 30;
store_output = zeros(length(p_loop),3); <span class="comment">% [population distance, RMT estimator, classical estimator]</span>

<span class="keyword">for</span> i = 1:length(p_loop)
    p = p_loop(i);

    C1 = toeplitz(0.2.^(0:p-1));
    C2 = toeplitz(0.4.^(0:p-1));

    f = @(z) log(z).^2; <span class="comment">% Fisher distance</span>

    tmp = zeros(3,1);
    <span class="keyword">for</span> j = 1:nb_average_loop
        X1 = sqrtm(C1)*randn(p,n1);
        X2 = sqrtm(C2)*randn(p,n2);

        [RMTDistEst,ClassDistEst] = RMTCovDistEst(X1,X2,<span class="string">'Fisher'</span>);
        tmp = tmp + [mean(f(eig(C1\C2))); RMTDistEst; ClassDistEst]/nb_average_loop;
    <span class="keyword">end</span>
    store_output(i,:) = tmp;
<span class="keyword">end</span>

disp(<span class="string">'Performance of different estimators:'</span>)
disp([p_loop', store_output])
</pre><h2 id="3">FUNCTIONS</h2><p>Code from https://github.com/maliktiomoko/RMTEstimCovDist</p><pre class="codeinput"><span class="keyword">function</span> [RMTDistEst,ClassDistEst] = RMTCovDistEst(X1,X2,distance)
<span class="comment">%RMTCovDistEst: random matrix-based improved estimators of distances</span>
<span class="comment">%between covariances</span>
<span class="comment">%INPUT: X1 (input data of covriance C1), X2 (input data of covriance C2),</span>
<span class="comment">%distance (different types of distances under consideration)</span>

n1=size(X1,2);
n2=size(X2,2);
p=size(X2,1);

<span class="keyword">switch</span> distance
    <span class="keyword">case</span> <span class="string">'Fisher'</span>
        f = @(t) log(t).^2;
    <span class="keyword">case</span> <span class="string">'bhattacharrya'</span>
        f = @(t) -1/4*log(t)+1/2*log(1+t)-1/2*log(2);
    <span class="keyword">case</span> <span class="string">'KL'</span>
        f = @(t) 1/2*t-1/2*log(t)-1/2;
    <span class="keyword">case</span> <span class="string">'t'</span>
        f = @(t) t;
    <span class="keyword">case</span> <span class="string">'log'</span>
        f = @(t) log(t);
    <span class="keyword">case</span> <span class="string">'log(1+st)'</span>
        s = 1;
        f = @(t) log(1+s*t);
<span class="keyword">end</span>
    c2=p/n2;
    c1=p/n1;
    hatC1=1/n1*(X1*X1');
    hatC2=1/n2*(X2*X2');
    F=hatC1\hatC2;

    lambda=sort(eig(F));
    slambda=sqrt(lambda);
    eta = sort(eig(diag(lambda)-slambda*slambda'/(p-n1)));
    zeta = sort(eig(diag(lambda)-slambda*slambda'/n2));
    m = @(z) mean(1./(lambda*ones(1,length(z))-ones(p,1)*z));
    phi=@(z) z+c1*z.^2.*m(z);
    psi=@(z) 1-c2-c2*z.*m(z);
    <span class="keyword">switch</span> distance
        <span class="keyword">case</span> <span class="string">'Fisher'</span>
            M=zeros(p);
                N=zeros(p);
                <span class="keyword">for</span> i=1:p
                    M(i,i)=1/(2*lambda(i)^2);
                    N(i,i)=1/lambda(i);
                    js=1:p;
                    js(i)=[];
                    <span class="keyword">for</span> j=js
                        M(i,j)=(-1+lambda(i)/lambda(j)-log(lambda(i)/lambda(j)))/(lambda(i)-lambda(j))^2;
                        N(i,j)=log(lambda(i)/lambda(j))/(lambda(i)-lambda(j));
                    <span class="keyword">end</span>
                <span class="keyword">end</span>

                <span class="comment">% Large p-estimate</span>

                RMTDistEst=2*(c1+c2-c1*c2)/(c1*c2)*( (eta-zeta)'*M*(eta-lambda)+(eta-lambda)'*(log((1-c1)*lambda)./lambda) )<span class="keyword">...</span>
                    -2/p*(eta-zeta)'*N*ones(p,1)+1/p*sum(log((1-c1)*lambda).^2)<span class="keyword">...</span>
                    -2*(1-c2)/c2*( 1/2*log( (1-c1)*(1-c2) )^2+(eta-zeta)'*(log((1-c1)*lambda)./lambda) );
                ClassDistEst=mean(f(lambda));
        <span class="keyword">case</span> <span class="string">'log(1+st)'</span>
            <span class="comment">% additional kappa term in negative side</span>
            s=1;
                kappa_p=0;
                kappa_m=-1/(s*(1-c1));
                <span class="keyword">if</span> c2&gt;1
                   kappa_p=min(lambda(lambda&gt;1e-3));
                   <span class="keyword">while</span> phi(kappa_m)/psi(kappa_m)&gt;-1/s
                       kappa_m=2*kappa_m;
                   <span class="keyword">end</span>
                <span class="keyword">end</span>

                <span class="keyword">while</span> abs(kappa_p-kappa_m)&gt;1e-6*abs(eta(p)-zeta(p))
                    kappa_=(kappa_p+kappa_m)/2;
                    <span class="keyword">if</span> phi(kappa_)/psi(kappa_)&lt;-1/s
                        kappa_m=kappa_;
                    <span class="keyword">else</span>
                        kappa_p=kappa_;
                    <span class="keyword">end</span>
                <span class="keyword">end</span>
                kappa_0=(kappa_p+kappa_m)/2;
            RMTDistEst=(c1+c2-c1*c2)/(c1*c2)*log((c1+c2-c1*c2)/(1-c1)/abs(c2-s*c1*kappa_0))+1/c2*log(abs(-s*kappa_0*(1-c1)))+1/p*sum(log(abs(1-lambda/kappa_0)));
            ClassDistEst=mean(f(lambda));
        <span class="keyword">case</span> <span class="string">'bhattacharrya'</span>
            RMTDistEst=(-1/4)*RMTCovDistEst(X,Y,<span class="string">'log'</span>)+1/2*RMTCovDistEst(X,Y,<span class="string">'log(1+st)'</span>)-1/2*log(2);
            ClassDistEst=mean(f(lambda));
        <span class="keyword">case</span> <span class="string">'KL'</span>
            RMTDistEst=1/2*((1-c1)*mean(lambda)-mean(log(lambda))+(1-c1)/c1*log(1-c1)-(1-c2)/c2*log(1-c2)-1);
            ClassDistEst=mean(f(lambda));
        <span class="keyword">case</span> <span class="string">'t'</span>
            RMTDistEst=(1-c1)*mean(lambda);
            ClassDistEst=mean(f(lambda));
        <span class="keyword">case</span> <span class="string">'log'</span>
            RMTDistEst=1/p*sum(log(lambda))-(1-c1)/c1*log(1-c1)+(1-c2)/c2*log(1-c2);
            ClassDistEst=mean(f(lambda));
        <span class="keyword">case</span> <span class="string">'Wasserstein'</span>
            [RMTDistEst,ClassDistEst]=RMTWassDist(X1,X2);
    <span class="keyword">end</span>

<span class="keyword">end</span>


<span class="keyword">function</span> [RMTDistEst,ClassDistEst] = RMTWassDist(X1,X2)
<span class="comment">%Function that compute the Wasserstein distance between Gaussian centered</span>
<span class="comment">%distribution based on the article Random  Matrix-Improved  Estimation  of  the  Wasserstein  Distance</span>
<span class="comment">%between  two  Centered  Gaussian  Distribution (Malik TIOMOKO &amp; Romain Couillet)</span>
<span class="comment">%Input samples from the first class X1 of dimension p*n1 and the</span>
<span class="comment">%samples from the second class X2 of size p*n2</span>

p=size(X1,1);
n1=size(X1,2);
n2=size(X2,2);
c1=p/n1;c2=p/n2;

<span class="comment">%Sample covariance estimate</span>
hatC1=X1*X1'/n1;hatC2=X2*X2'/n2;
lambda=sort(eig(hatC1*hatC2));
m=@(z) mean(1./(lambda-z));
phi=@(z) z./(1-c1-c1.*z.*m(z));
psi=@(z) 1-c2-c2*z.*m(z);
f=@(z) sqrt(z);
eta=sort(real(eig(diag(lambda)-(1/n1)*sqrt(lambda)*sqrt(lambda)')));
zeta=sort(real(eig(diag(lambda)-(1/n2)*sqrt(lambda)*sqrt(lambda)')));
phi_test=@(z) z;
psi_test=@(z) 1;
phipsi=@(z) sqrt(z)/(c2);
<span class="keyword">for</span> i=1:length(lambda)
    phi_test=@(z) phi_test(z).*((z-lambda(i))./(z-eta(i)));
    psi_test=@(z) psi_test(z).*(z-zeta(i))./(z-lambda(i));
    phipsi=@(z) phipsi(z).*sqrt((z-zeta(i))./(z-eta(i)));
<span class="keyword">end</span>
<span class="comment">% Distinguish the case where n1&lt;n2 to the case where n1&gt;n2</span>
<span class="keyword">if</span> eta(1)&lt;zeta(1)
    my_eta=zeta;
    my_zeta=eta;
<span class="keyword">else</span>
    my_zeta=zeta;
    my_eta=eta;
<span class="keyword">end</span>
other=@(z) 2*sum(1./(z-zeta))-2*sum(1./(z-lambda));
integrand_real=@(z) (1/(2*pi))*2*f(-(phi(z)./psi(z))).*other(z).*(psi(z)/c2);
<span class="comment">%Computing the second term (real_integral)</span>
real_integral=0;
<span class="keyword">for</span> i=1:length(my_zeta)
    real_integral=real_integral+integral(integrand_real,my_zeta(i),my_eta(i));
<span class="keyword">end</span>
<span class="comment">%Computing the first term (pole in lambda)</span>
pole=2*(sqrt(c2/c1))*sum(sqrt(lambda))/c2;
esty=pole+real_integral;
RMTDistEst=(1/p)*trace(hatC1+hatC2)-2*esty;
<span class="comment">%Distinguish the case n1=n2</span>
<span class="keyword">if</span> n1==n2
    RMTDistEst=(1/p)*trace(hatC1+hatC2)-2*(sum(sqrt(lambda))-sum(sqrt(zeta)))*(2*n1/p);
<span class="keyword">end</span>

<span class="comment">%Classical estimate</span>
ClassDistEst=(1/p)*(trace(hatC1)+trace(hatC2)-2*trace((hatC1^(1/2)*hatC2*hatC1^(1/2))^(1/2)));
<span class="keyword">end</span>
</pre><pre class="codeoutput">Performance of different estimators:
    2.0000    0.0533    0.0524    0.0568
    4.0000    0.0796    0.0840    0.0913
    8.0000    0.0927    0.0917    0.1048
   16.0000    0.0992    0.1007    0.1253
   32.0000    0.1025    0.1029    0.1509
   64.0000    0.1042    0.1049    0.2009
  128.0000    0.1050    0.1044    0.3023
  256.0000    0.1054    0.1057    0.5341
  512.0000    0.1056    0.1086    1.1556

</pre><p class="footer"><br><a href="https://www.mathworks.com/products/matlab/">Published with MATLAB&reg; R2019a</a><br></p></div><!--
##### SOURCE BEGIN #####
%% Section 3.2: Covariance distance estimation
% This page contains simulations in Section 3.2: estimation of various
% distance between covariance matrices in large dimension

%% Visualization of behavior of $x \mapsto x m_\mu(x)$
close all; clear; clc

coeff = 3;
p = 100*coeff;
n1 = 300*coeff;
n2 = 900*coeff;

c1 = p/n1;
c2 = p/n2;

rng(928);
Z1 = randn(p,n1);
Z2 = randn(p,n2);

eig_C1 = [1,2,4];
eig_C2 = [1,3,5];
C1 = diag([eig_C1(1)*ones(p/3,1); eig_C1(2)*ones(p/3,1); eig_C1(3)*ones(p/3,1)]); 
C2 = diag([eig_C2(1)*ones(p/3,1); eig_C2(2)*ones(p/3,1); eig_C2(3)*ones(p/3,1)]); 

X1 = sqrtm(C1)*Z1;
X2 = sqrtm(C2)*Z2;

SCM1 = X1*(X1')/n1;
SCM2 = X2*(X2')/n2;

SCM = SCM1\SCM2;
eigs_SCM = eig(SCM);
eigs_SCM = sort(eigs_SCM);

m = @(x) sum(1./(eigs_SCM-x))/p;
x_m = @(x) x.*m(x);

tol1 = 1e-3;
index_eigs_SCM = 50;
zoom_eigs_SCM = linspace(eigs_SCM(index_eigs_SCM)-tol1,eigs_SCM(index_eigs_SCM+1)+tol1,1000);

tol2 = 1e-4;
zoom_eigs_SCM(zoom_eigs_SCM<=eigs_SCM(index_eigs_SCM)+tol2 & zoom_eigs_SCM>=eigs_SCM(index_eigs_SCM)-tol2)=NaN;
zoom_eigs_SCM(zoom_eigs_SCM<=eigs_SCM(index_eigs_SCM+1)+tol2 & zoom_eigs_SCM>=eigs_SCM(index_eigs_SCM+1)-tol2)=NaN;

% numerical evaluation of eta and zeta
eta = real(eig(diag(eigs_SCM) + sqrt(eigs_SCM)*sqrt(eigs_SCM')/(n1-p)));
eta = eta(eta<eigs_SCM(index_eigs_SCM+1) & eta>eigs_SCM(index_eigs_SCM));
zeta = real(eig(diag(eigs_SCM) - sqrt(eigs_SCM)*sqrt(eigs_SCM')/(n2)));
zeta = zeta(zeta<eigs_SCM(index_eigs_SCM) & zeta>eigs_SCM(index_eigs_SCM-1));

figure
hold on
plot(zoom_eigs_SCM, x_m(zoom_eigs_SCM));
xline(eigs_SCM(index_eigs_SCM),'REPLACE_WITH_DASH_DASHk');
xline(eigs_SCM(index_eigs_SCM+1),'REPLACE_WITH_DASH_DASHk');
yline(0,'REPLACE_WITH_DASH_DASHk');
yline( (1-c2)/c2,'REPLACE_WITH_DASH_DASHk');
yline( -1/c1,'REPLACE_WITH_DASH_DASHk');
yline(0,'REPLACE_WITH_DASH_DASHk');
axis([eigs_SCM(index_eigs_SCM)-tol1 eigs_SCM(index_eigs_SCM+1)+tol1 -10 10])

xlabel('x', 'Interpreter', 'latex')
ylabel('$x m_{\mu}(x)$', 'Interpreter', 'latex')
plot(eigs_SCM(index_eigs_SCM),0,'ob');
text(eigs_SCM(index_eigs_SCM)+1e-5,.5,'$\lambda_i$', 'Interpreter', 'latex', 'FontSize',12)
plot(eigs_SCM(index_eigs_SCM+1),0,'ob');
text(eigs_SCM(index_eigs_SCM+1)+1e-5,.5,'$\lambda_{i+1}$', 'Interpreter', 'latex', 'FontSize',12)

plot(eta, 0,'xr');
plot(zeta, 0,'xr');
text(eta-1e-4, .5,'$\eta_i$', 'Interpreter', 'latex', 'FontSize',12)
text(zeta-1e-4, .5,'$\zeta_i$', 'Interpreter', 'latex', 'FontSize',12)
xline(eta,':k');
xline(zeta,':k');

%% Classical versus random matrix improved covariance distance estimator
close all; clear; clc

p_loop = 2.^(1:9);
n1 = 1024;
n2 = 2048;

rng(928);
nb_average_loop = 30;
store_output = zeros(length(p_loop),3); % [population distance, RMT estimator, classical estimator]

for i = 1:length(p_loop)
    p = p_loop(i);
    
    C1 = toeplitz(0.2.^(0:p-1));
    C2 = toeplitz(0.4.^(0:p-1));

    f = @(z) log(z).^2; % Fisher distance
    
    tmp = zeros(3,1);
    for j = 1:nb_average_loop
        X1 = sqrtm(C1)*randn(p,n1);
        X2 = sqrtm(C2)*randn(p,n2);

        [RMTDistEst,ClassDistEst] = RMTCovDistEst(X1,X2,'Fisher');
        tmp = tmp + [mean(f(eig(C1\C2))); RMTDistEst; ClassDistEst]/nb_average_loop;
    end
    store_output(i,:) = tmp;
end        

disp('Performance of different estimators:')
disp([p_loop', store_output])

%% FUNCTIONS
% Code from https://github.com/maliktiomoko/RMTEstimCovDist
function [RMTDistEst,ClassDistEst] = RMTCovDistEst(X1,X2,distance)
%RMTCovDistEst: random matrix-based improved estimators of distances
%between covariances
%INPUT: X1 (input data of covriance C1), X2 (input data of covriance C2),
%distance (different types of distances under consideration)

n1=size(X1,2);
n2=size(X2,2);
p=size(X2,1);

switch distance
    case 'Fisher'
        f = @(t) log(t).^2;
    case 'bhattacharrya'
        f = @(t) -1/4*log(t)+1/2*log(1+t)-1/2*log(2);
    case 'KL'
        f = @(t) 1/2*t-1/2*log(t)-1/2;
    case 't'
        f = @(t) t;
    case 'log'
        f = @(t) log(t);
    case 'log(1+st)'
        s = 1;
        f = @(t) log(1+s*t);
end    
    c2=p/n2;
    c1=p/n1;                   
    hatC1=1/n1*(X1*X1');
    hatC2=1/n2*(X2*X2');
    F=hatC1\hatC2;

    lambda=sort(eig(F));
    slambda=sqrt(lambda);
    eta = sort(eig(diag(lambda)-slambda*slambda'/(p-n1)));
    zeta = sort(eig(diag(lambda)-slambda*slambda'/n2));
    m = @(z) mean(1./(lambda*ones(1,length(z))-ones(p,1)*z));        
    phi=@(z) z+c1*z.^2.*m(z);      
    psi=@(z) 1-c2-c2*z.*m(z);
    switch distance
        case 'Fisher'
            M=zeros(p);
                N=zeros(p);                
                for i=1:p
                    M(i,i)=1/(2*lambda(i)^2);
                    N(i,i)=1/lambda(i);                 
                    js=1:p;
                    js(i)=[];
                    for j=js
                        M(i,j)=(-1+lambda(i)/lambda(j)-log(lambda(i)/lambda(j)))/(lambda(i)-lambda(j))^2;                        
                        N(i,j)=log(lambda(i)/lambda(j))/(lambda(i)-lambda(j));
                    end
                end     

                % Large p-estimate
                
                RMTDistEst=2*(c1+c2-c1*c2)/(c1*c2)*( (eta-zeta)'*M*(eta-lambda)+(eta-lambda)'*(log((1-c1)*lambda)./lambda) )...
                    -2/p*(eta-zeta)'*N*ones(p,1)+1/p*sum(log((1-c1)*lambda).^2)...
                    -2*(1-c2)/c2*( 1/2*log( (1-c1)*(1-c2) )^2+(eta-zeta)'*(log((1-c1)*lambda)./lambda) );               
                ClassDistEst=mean(f(lambda));
        case 'log(1+st)'  
            % additional kappa term in negative side
            s=1;
                kappa_p=0;
                kappa_m=-1/(s*(1-c1));
                if c2>1
                   kappa_p=min(lambda(lambda>1e-3));
                   while phi(kappa_m)/psi(kappa_m)>-1/s
                       kappa_m=2*kappa_m;
                   end
                end
                
                while abs(kappa_p-kappa_m)>1e-6*abs(eta(p)-zeta(p))
                    kappa_=(kappa_p+kappa_m)/2;
                    if phi(kappa_)/psi(kappa_)<-1/s
                        kappa_m=kappa_;
                    else
                        kappa_p=kappa_;
                    end
                end
                kappa_0=(kappa_p+kappa_m)/2;  
            RMTDistEst=(c1+c2-c1*c2)/(c1*c2)*log((c1+c2-c1*c2)/(1-c1)/abs(c2-s*c1*kappa_0))+1/c2*log(abs(-s*kappa_0*(1-c1)))+1/p*sum(log(abs(1-lambda/kappa_0)));  
            ClassDistEst=mean(f(lambda));
        case 'bhattacharrya'
            RMTDistEst=(-1/4)*RMTCovDistEst(X,Y,'log')+1/2*RMTCovDistEst(X,Y,'log(1+st)')-1/2*log(2);
            ClassDistEst=mean(f(lambda));
        case 'KL'
            RMTDistEst=1/2*((1-c1)*mean(lambda)-mean(log(lambda))+(1-c1)/c1*log(1-c1)-(1-c2)/c2*log(1-c2)-1);
            ClassDistEst=mean(f(lambda));
        case 't'
            RMTDistEst=(1-c1)*mean(lambda);
            ClassDistEst=mean(f(lambda));
        case 'log'
            RMTDistEst=1/p*sum(log(lambda))-(1-c1)/c1*log(1-c1)+(1-c2)/c2*log(1-c2);
            ClassDistEst=mean(f(lambda));
        case 'Wasserstein'
            [RMTDistEst,ClassDistEst]=RMTWassDist(X1,X2);
    end

end


function [RMTDistEst,ClassDistEst] = RMTWassDist(X1,X2)
%Function that compute the Wasserstein distance between Gaussian centered
%distribution based on the article Random  Matrix-Improved  Estimation  of  the  Wasserstein  Distance
%between  two  Centered  Gaussian  Distribution (Malik TIOMOKO & Romain Couillet)
%Input samples from the first class X1 of dimension p*n1 and the
%samples from the second class X2 of size p*n2

p=size(X1,1);
n1=size(X1,2);
n2=size(X2,2);
c1=p/n1;c2=p/n2;

%Sample covariance estimate
hatC1=X1*X1'/n1;hatC2=X2*X2'/n2;
lambda=sort(eig(hatC1*hatC2));
m=@(z) mean(1./(lambda-z));
phi=@(z) z./(1-c1-c1.*z.*m(z));
psi=@(z) 1-c2-c2*z.*m(z);
f=@(z) sqrt(z);
eta=sort(real(eig(diag(lambda)-(1/n1)*sqrt(lambda)*sqrt(lambda)')));
zeta=sort(real(eig(diag(lambda)-(1/n2)*sqrt(lambda)*sqrt(lambda)')));
phi_test=@(z) z;
psi_test=@(z) 1;
phipsi=@(z) sqrt(z)/(c2);
for i=1:length(lambda)
    phi_test=@(z) phi_test(z).*((z-lambda(i))./(z-eta(i)));
    psi_test=@(z) psi_test(z).*(z-zeta(i))./(z-lambda(i));
    phipsi=@(z) phipsi(z).*sqrt((z-zeta(i))./(z-eta(i)));
end
% Distinguish the case where n1<n2 to the case where n1>n2
if eta(1)<zeta(1)
    my_eta=zeta;
    my_zeta=eta;
else
    my_zeta=zeta;
    my_eta=eta;
end
other=@(z) 2*sum(1./(z-zeta))-2*sum(1./(z-lambda));
integrand_real=@(z) (1/(2*pi))*2*f(-(phi(z)./psi(z))).*other(z).*(psi(z)/c2);
%Computing the second term (real_integral)
real_integral=0;
for i=1:length(my_zeta)
    real_integral=real_integral+integral(integrand_real,my_zeta(i),my_eta(i));
end
%Computing the first term (pole in lambda)
pole=2*(sqrt(c2/c1))*sum(sqrt(lambda))/c2;
esty=pole+real_integral;
RMTDistEst=(1/p)*trace(hatC1+hatC2)-2*esty;
%Distinguish the case n1=n2
if n1==n2
    RMTDistEst=(1/p)*trace(hatC1+hatC2)-2*(sum(sqrt(lambda))-sum(sqrt(zeta)))*(2*n1/p);
end

%Classical estimate
ClassDistEst=(1/p)*(trace(hatC1)+trace(hatC2)-2*trace((hatC1^(1/2)*hatC2*hatC1^(1/2))^(1/2)));
end

##### SOURCE END #####
--></body></html>